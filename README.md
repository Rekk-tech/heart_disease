# Heart Disease Prediction Project

A comprehensive machine learning project for predicting heart disease risk using various algorithms and advanced techniques.

## ğŸ¯ Project Overview

This project implements a complete machine learning pipeline for heart disease prediction, including:

- **Data Analysis**: Comprehensive exploratory data analysis and visualization
- **Feature Engineering**: Advanced feature creation and selection techniques
- **Model Training**: Multiple algorithms including Naive Bayes, KNN, Decision Trees, and Ensemble methods
- **Model Evaluation**: Comprehensive evaluation with multiple metrics and visualizations
- **Model Explainability**: SHAP, LIME, and permutation importance analysis
- **Deployment**: FastAPI backend and Streamlit frontend for real-time predictions

## ğŸ“Š Dataset

The project uses the Cleveland Heart Disease Dataset with the following features:

- **Demographic**: Age, Sex
- **Medical History**: Chest pain type, resting blood pressure, cholesterol, fasting blood sugar
- **Test Results**: Resting ECG, maximum heart rate, exercise-induced angina, ST depression, slope, major vessels, thalassemia
- **Target**: Heart disease presence (0: No disease, 1: Disease)

## ğŸ—ï¸ Project Structure

```
heart_disease_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Heart_disease_cleveland_new.csv
â”‚   â”œâ”€â”€ interim/                     # Intermediate processed data
â”‚   â””â”€â”€ processed/                   # Train/val/test splits, feature store
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                 # EDA, statistics, class balance
â”‚   â”œâ”€â”€ 02_visualization.ipynb       # Advanced visualizations
â”‚   â”œâ”€â”€ 03_modeling.ipynb            # Compare NB, KNN, DT, Ensemble
â”‚   â””â”€â”€ 04_explainability.ipynb      # SHAP / permutation importance
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py               # Load/validate data schema
â”‚   â”œâ”€â”€ preprocessing.py             # Split + ColumnTransformer
â”‚   â”œâ”€â”€ feature_engineering.py       # Feature creation and selection
â”‚   â”œâ”€â”€ modeling.py                  # NB, KNN, DT, VotingClassifier
â”‚   â”œâ”€â”€ evaluation.py                # ACC, F1, ROC-AUC, CM + plots
â”‚   â”œâ”€â”€ persistence.py               # Save/load artifacts
â”‚   â”œâ”€â”€ explain.py                   # SHAP/permutation/LIME
â”‚   â””â”€â”€ utils.py                     # Logger, seed, configuration
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ heart_model.pkl              # Trained ensemble model
â”‚   â”œâ”€â”€ preprocessor.pkl             # ColumnTransformer
â”‚   â”œâ”€â”€ quantiles.json               # Numeric feature percentiles
â”‚   â””â”€â”€ model_card.md                # Model description
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py                       # FastAPI: /predict, /meta
â”‚   â””â”€â”€ ui_streamlit.py              # Streamlit form input & results
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ config.yaml                  # Paths + numeric/categorical columns
â”‚   â””â”€â”€ params.yaml                  # Model hyperparameters
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_modeling.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile                         # make train | api | ui | test
â””â”€â”€ run_pipeline.py                  # Run full end-to-end pipeline
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone the repository
git clone <repository-url>
cd heart_disease_project

# Install dependencies
make setup
# or
pip install -r requirements.txt
```

### 2. Run Complete Pipeline

```bash
# Run the entire ML pipeline
make pipeline
# or
python run_pipeline.py
```

### 3. Start Applications

```bash
# Start API server (Terminal 1)
make api
# or
python app/api.py

# Start Streamlit UI (Terminal 2)
make ui
# or
streamlit run app/ui_streamlit.py
```

### 4. Access Applications

- **API Documentation**: http://localhost:8000/docs
- **Streamlit UI**: http://localhost:8501

## ğŸ“‹ Available Commands

### Setup and Installation
```bash
make setup          # Install dependencies
make setup-dev      # Install development dependencies
```

### Data Operations
```bash
make data           # Load and validate data
make preprocess     # Preprocess data and create splits
```

### Model Training and Evaluation
```bash
make train          # Train models and create ensemble
make evaluate       # Evaluate models and generate reports
make explain        # Generate model explanations
```

### Applications
```bash
make api            # Start FastAPI server (localhost:8000)
make ui             # Start Streamlit UI (localhost:8501)
```

### Testing and Quality
```bash
make test           # Run all tests
make test-coverage  # Run tests with coverage report
make lint           # Run linting checks
make format         # Format code with black
```

### Jupyter Notebooks
```bash
make notebooks      # Start Jupyter server
make notebook-eda   # Open EDA notebook
make notebook-viz   # Open visualization notebook
make notebook-modeling # Open modeling notebook
make notebook-explain # Open explainability notebook
```

### Cleaning
```bash
make clean          # Clean temporary files
make clean-all      # Clean all generated files
```

## ğŸ”§ Configuration

The project uses YAML configuration files:

- **`conf/config.yaml`**: Main configuration with paths, features, and settings
- **`conf/params.yaml`**: Hyperparameters for models and training

Key configuration sections:
- Data paths and feature definitions
- Model parameters and hyperparameters
- Evaluation metrics and cross-validation settings
- API and logging configuration

## ğŸ§ª Testing

Run comprehensive tests:

```bash
# Run all tests
make test

# Run with coverage
make test-coverage

# Run specific test modules
python -m pytest tests/test_preprocessing.py -v
python -m pytest tests/test_modeling.py -v
python -m pytest tests/test_api.py -v
```

## ğŸ“Š Model Performance

The ensemble model typically achieves:
- **Accuracy**: ~85-90%
- **F1 Score**: ~0.85-0.90
- **ROC-AUC**: ~0.90-0.95

## ğŸ” Model Explainability

The project includes comprehensive model interpretability:

- **Feature Importance**: Tree-based feature importance
- **Permutation Importance**: Cross-validated feature importance
- **SHAP Values**: SHapley Additive exPlanations
- **LIME**: Local Interpretable Model-agnostic Explanations
- **Partial Dependence**: Feature effect analysis

## ğŸŒ API Usage

### Predict Single Instance

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "age": 50,
       "sex": 1,
       "cp": 0,
       "trestbps": 120,
       "chol": 200,
       "fbs": 0,
       "restecg": 0,
       "thalach": 150,
       "exang": 0,
       "oldpeak": 1.0,
       "slope": 1,
       "ca": 0,
       "thal": 0
     }'
```

### Batch Prediction

```bash
curl -X POST "http://localhost:8000/batch-predict" \
     -H "Content-Type: application/json" \
     -d '[{...}, {...}]'
```

### Get Model Information

```bash
curl -X GET "http://localhost:8000/model-info"
```

## ğŸ› ï¸ Development

### Code Quality

```bash
# Format code
make format

# Run linting
make lint

# Type checking
make type-check
```

### Development Setup

```bash
# Setup development environment
make dev-setup

# Run CI pipeline
make ci
```

## ğŸ“ˆ Monitoring and Logging

- **Logs**: Stored in `logs/heart_disease.log`
- **Plots**: Saved in `plots/` directory
- **Model Artifacts**: Stored in `models/` directory

## âš ï¸ Important Notes

### Medical Disclaimer

**This tool is for educational and research purposes only. It should not be used as a substitute for professional medical advice, diagnosis, or treatment. Always consult with qualified healthcare professionals for medical decisions.**

### Data Privacy

- The dataset contains anonymized medical data
- No personal identifiers are included
- All analysis is performed locally

### Model Limitations

- Trained on specific dataset and may not generalize to other populations
- Requires complete feature information for accurate predictions
- Clinical decisions should not be based solely on model predictions

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Cleveland Heart Disease Dataset
- Scikit-learn library
- FastAPI and Streamlit frameworks
- SHAP and LIME libraries for model interpretability

## ğŸ“ Support

For questions or issues:
1. Check the documentation
2. Review existing issues
3. Create a new issue with detailed information

---

**Made with â¤ï¸ for healthcare and machine learning education**
